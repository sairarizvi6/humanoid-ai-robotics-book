<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-sensors-in-physical-ai" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.3">
<title data-rh="true">Sensors in Physical AI | Physical AI &amp; Humanoid Robotics: Bridging Digital Intelligence and the Physical World</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://phys-git-main-sairarizvi6-projects.vercel.app/sensors-in-physical-ai"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="chat-api" content="https://phys-chatbot-api.vercel.app/chat"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Sensors in Physical AI | Physical AI &amp; Humanoid Robotics: Bridging Digital Intelligence and the Physical World"><meta data-rh="true" name="description" content="The Eyes, Ears, and Touch of a Robot"><meta data-rh="true" property="og:description" content="The Eyes, Ears, and Touch of a Robot"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://phys-git-main-sairarizvi6-projects.vercel.app/sensors-in-physical-ai"><link data-rh="true" rel="alternate" href="https://phys-git-main-sairarizvi6-projects.vercel.app/sensors-in-physical-ai" hreflang="en"><link data-rh="true" rel="alternate" href="https://phys-git-main-sairarizvi6-projects.vercel.app/sensors-in-physical-ai" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.0a5f47d9.css">
<link rel="preload" href="/assets/js/runtime~main.a22e79de.js" as="script">
<link rel="preload" href="/assets/js/main.8e1e1db1.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><b class="navbar__title text--truncate">Physical AI &amp; Humanoid Robotics</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/introduction-to-physical-ai">Textbook</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/panaversity/ai-robotics-textbook" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/introduction-to-physical-ai">Introduction to Physical AI</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/embodied-intelligence-and-humanoids">Embodied Intelligence and Humanoids</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ros2-the-robotic-nervous-system">ROS 2 - The Robotic Nervous System</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/urdf-and-robot-description">URDF and Robot Description</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" href="/sensors-in-physical-ai">Sensors in Physical AI</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/simulation-with-gazebo">Simulation with Gazebo</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/nvidia-isaac-sim-and-digital-twins">NVIDIA Isaac Sim and Digital Twins</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/isaac-ros-and-perception">Isaac ROS and Perception</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/navigation-and-bipedal-locomotion">Navigation and Bipedal Locomotion</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/vision-language-action-models">Vision-Language-Action Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/conversational-robotics-voice-to-action">Conversational Robotics - Voice to Action</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/balance-manipulation-and-whole-body-control">Balance, Manipulation, and Whole-Body Control</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/capstone-autonomous-humanoid">Capstone - Autonomous Humanoid</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/recommended-humanoid-robots">Recommended Humanoid Robots</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/student-hardware-guide">Student Hardware Guide</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/">Welcome to Physical AI &amp; Humanoid Robotics</a></li></ul></nav></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Sensors in Physical AI</span><meta itemprop="position" content="1"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Chapter 5: Sensors in Physical AI</h1><h2 class="anchor anchorWithStickyNavbar_LWe7" id="the-eyes-ears-and-touch-of-a-robot">The Eyes, Ears, and Touch of a Robot<a href="#the-eyes-ears-and-touch-of-a-robot" class="hash-link" aria-label="Direct link to The Eyes, Ears, and Touch of a Robot" title="Direct link to The Eyes, Ears, and Touch of a Robot">​</a></h2><p>For a physical AI system to interact intelligently with the real world, it must first be able to perceive it. <strong>Sensors</strong> are the fundamental components that enable robots to gather information about their own state and their surrounding environment. Just as humans rely on sight, hearing, and touch, robots employ an array of sophisticated sensors to build a rich, internal representation of the world, which then informs their decision-making and actions. The choice and integration of sensors are critical for the success of any humanoid or physical AI application.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="importance-of-sensory-perception">Importance of Sensory Perception<a href="#importance-of-sensory-perception" class="hash-link" aria-label="Direct link to Importance of Sensory Perception" title="Direct link to Importance of Sensory Perception">​</a></h3><ul><li><strong>Environmental Understanding</strong>: Sensors provide data about objects, obstacles, surfaces, and human presence.</li><li><strong>Localization and Mapping (SLAM)</strong>: Enables robots to know where they are and to build maps of unknown environments.</li><li><strong>Object Recognition and Tracking</strong>: Essential for manipulation, interaction, and navigation.</li><li><strong>Internal State Monitoring</strong>: Feedback on joint angles, motor currents, battery levels, and other vital robot parameters.</li><li><strong>Safety</strong>: Detecting potential hazards and ensuring safe operation around humans and other robots.</li></ul><div class="language-mermaid codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-mermaid codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">graph TD</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    A[Physical World] --&gt; B(Sensors)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    B --&gt; C{Raw Data}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    C --&gt; D[Perception Module (e.g., Image Processing, Point Cloud Filtering)]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    D --&gt; E[Information (e.g., Object Position, Robot Pose)]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    E --&gt; F[Decision Making &amp; Control]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    F --&gt; G[Robot Actions]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><em>Figure 5.1: Sensory data flow in a physical AI system.</em></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="categories-of-sensors">Categories of Sensors<a href="#categories-of-sensors" class="hash-link" aria-label="Direct link to Categories of Sensors" title="Direct link to Categories of Sensors">​</a></h2><p>Sensors in robotics can be broadly categorized into proprioceptive (sensing the robot&#x27;s internal state) and exteroceptive (sensing the external environment).</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="51-proprioceptive-sensors">5.1. Proprioceptive Sensors<a href="#51-proprioceptive-sensors" class="hash-link" aria-label="Direct link to 5.1. Proprioceptive Sensors" title="Direct link to 5.1. Proprioceptive Sensors">​</a></h3><p>These sensors measure the robot&#x27;s own state. They are crucial for control, balance, and understanding the robot&#x27;s configuration.</p><ul><li><strong>Encoders</strong>: Measure the angular position or velocity of motor shafts and joints. Essential for precise joint control and kinematic calculations.<ul><li><em>ROS 2 Message Type</em>: <code>sensor_msgs/msg/JointState</code></li></ul></li><li><strong>Inertial Measurement Units (IMUs)</strong>: Combine accelerometers, gyroscopes, and sometimes magnetometers to measure linear acceleration, angular velocity, and orientation. Critical for maintaining balance and estimating robot pose, especially in dynamic movements like walking.<ul><li><em>ROS 2 Message Type</em>: <code>sensor_msgs/msg/Imu</code></li></ul></li><li><strong>Force/Torque Sensors</strong>: Measure forces and torques applied at specific points, such as robot wrists or feet. Provides feedback for compliant manipulation, detecting contact, and weight distribution for bipedal balance.<ul><li><em>ROS 2 Message Type</em>: <code>geometry_msgs/msg/WrenchStamped</code></li></ul></li><li><strong>Tactile Sensors</strong>: Arrays of pressure-sensitive elements providing a sense of touch, often used in grippers and fingertips for delicate object handling or surface texture recognition.<ul><li><em>ROS 2 Message Type</em>: Custom messages, often based on <code>sensor_msgs/msg/PointCloud2</code> or <code>sensor_msgs/msg/Image</code> for grid-like data.</li></ul></li></ul><div class="language-mermaid codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-mermaid codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">classDiagram</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    class ProprioceptiveSensor {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        + measureInternalState()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    class Encoder {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        + measureJointPosition()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    class IMU {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        + measureOrientation()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        + measureAcceleration()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    class ForceTorqueSensor {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        + measureForceTorque()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    class TactileSensor {</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        + measurePressureDistribution()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ProprioceptiveSensor &lt;|-- Encoder</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ProprioceptiveSensor &lt;|-- IMU</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ProprioceptiveSensor &lt;|-- ForceTorqueSensor</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ProprioceptiveSensor &lt;|-- TactileSensor</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><em>Figure 5.2: Hierarchy of proprioceptive sensors.</em></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="52-exteroceptive-sensors">5.2. Exteroceptive Sensors<a href="#52-exteroceptive-sensors" class="hash-link" aria-label="Direct link to 5.2. Exteroceptive Sensors" title="Direct link to 5.2. Exteroceptive Sensors">​</a></h3><p>These sensors gather information about the external environment. They are vital for navigation, obstacle avoidance, and interaction with objects and people.</p><ul><li><strong>Cameras</strong>: Capture 2D image data. Widely used for object recognition, facial recognition, gesture interpretation, visual servoing, and more. RGB, grayscale, and infrared cameras are common.<ul><li><em>ROS 2 Message Type</em>: <code>sensor_msgs/msg/Image</code>, <code>sensor_msgs/msg/CameraInfo</code></li></ul></li><li><strong>Depth Cameras (RGB-D)</strong>: Provide both color images (RGB) and per-pixel depth information. Technologies like Structured Light (e.g., Intel RealSense) or Time-of-Flight (ToF) (e.g., Azure Kinect) are used. Essential for 3D perception, object pose estimation, and obstacle avoidance.<ul><li><em>ROS 2 Message Type</em>: <code>sensor_msgs/msg/Image</code> (for depth), <code>sensor_msgs/msg/PointCloud2</code></li></ul></li><li><strong>Lidar (Light Detection and Ranging)</strong>: Uses pulsed lasers to measure distances to surfaces, generating dense 3D point clouds. Excellent for accurate mapping, localization, and long-range obstacle detection.<ul><li><em>ROS 2 Message Type</em>: <code>sensor_msgs/msg/PointCloud2</code>, <code>sensor_msgs/msg/LaserScan</code></li></ul></li><li><strong>Radar</strong>: Uses radio waves to detect objects and measure their velocity and range, often robust in adverse weather conditions where lidar/cameras struggle.<ul><li><em>ROS 2 Message Type</em>: Custom or <code>sensor_msgs/msg/PointCloud2</code></li></ul></li><li><strong>Microphones</strong>: Capture audio data for speech recognition, sound localization, and understanding environmental cues, enabling conversational robotics.<ul><li><em>ROS 2 Message Type</em>: <code>audio_common_msgs/msg/AudioData</code></li></ul></li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="sensor-fusion-the-holistic-view">Sensor Fusion: The Holistic View<a href="#sensor-fusion-the-holistic-view" class="hash-link" aria-label="Direct link to Sensor Fusion: The Holistic View" title="Direct link to Sensor Fusion: The Holistic View">​</a></h2><p>No single sensor can provide a complete and perfectly reliable understanding of the environment. <strong>Sensor fusion</strong> is the process of combining data from multiple sensors to obtain a more accurate, robust, and comprehensive perception than any individual sensor could provide alone. For humanoids, fusing data from IMUs for pose estimation, cameras for object recognition, and depth sensors for obstacle avoidance is crucial.</p><p>Techniques for sensor fusion include:</p><ul><li><strong>Kalman Filters / Extended Kalman Filters (EKF)</strong>: Used for state estimation (e.g., robot pose) by combining noisy sensor measurements over time.</li><li><strong>Particle Filters</strong>: Effective for localization in complex environments, particularly in probabilistic robotics.</li><li><strong>Deep Learning</strong>: Neural networks can directly learn to fuse heterogeneous sensor data for tasks like object detection or scene understanding.</li></ul><div class="language-mermaid codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-mermaid codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">graph LR</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    C1[Camera 1] --&gt; F{Sensor Fusion Module}</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    C2[Camera 2] --&gt; F</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    L[Lidar] --&gt; F</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    I[IMU] --&gt; F</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    F --&gt; O[Enhanced Environmental Model]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><em>Figure 5.3: Conceptual diagram of sensor fusion.</em></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="sensor-data-processing-in-ros-2">Sensor Data Processing in ROS 2<a href="#sensor-data-processing-in-ros-2" class="hash-link" aria-label="Direct link to Sensor Data Processing in ROS 2" title="Direct link to Sensor Data Processing in ROS 2">​</a></h2><p>ROS 2 provides standard message types and tools to work with sensor data. For example, processing a camera image:</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token comment" style="color:rgb(98, 114, 164)"># Basic ROS 2 Python image subscriber</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> rclpy</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> rclpy</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">node </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> Node</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> sensor_msgs</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">msg </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> Image</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> cv_bridge </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> CvBridge</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> cv2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">class</span><span class="token plain"> </span><span class="token class-name">ImageSubscriber</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">Node</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(80, 250, 123)">__init__</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token builtin" style="color:rgb(189, 147, 249)">super</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">__init__</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;image_subscriber&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">subscription </span><span class="token operator">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">create_subscription</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            Image</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            </span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;topic_image_raw&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">listener_callback</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            </span><span class="token number">10</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">subscription  </span><span class="token comment" style="color:rgb(98, 114, 164)"># prevent unused variable warning</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">br </span><span class="token operator">=</span><span class="token plain"> CvBridge</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(80, 250, 123)">listener_callback</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> data</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">get_logger</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">info</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;Receiving video frame&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        current_frame </span><span class="token operator">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">br</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">imgmsg_to_cv2</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">data</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        cv2</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">imshow</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;camera&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> current_frame</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        cv2</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">waitKey</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">1</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(80, 250, 123)">main</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">args</span><span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    rclpy</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">init</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">args</span><span class="token operator">=</span><span class="token plain">args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    image_subscriber </span><span class="token operator">=</span><span class="token plain"> ImageSubscriber</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    rclpy</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">spin</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">image_subscriber</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    image_subscriber</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">destroy_node</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    rclpy</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">shutdown</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">if</span><span class="token plain"> __name__ </span><span class="token operator">==</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;__main__&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    main</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><em>Code 5.1: A ROS 2 Python node to subscribe to and display camera images.</em></p><p>This snippet demonstrates subscribing to an <code>Image</code> topic and using <code>cv_bridge</code> to convert the ROS 2 image message into an OpenCV format for processing and display.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">​</a></h2><p>Sensors are the lifeline of any physical AI and humanoid robot, providing the essential input for intelligent behavior. A comprehensive understanding of different sensor types, their capabilities, and how to effectively fuse their data is paramount for developing robots that can robustly perceive, understand, and navigate the complexities of the real world. As AI advances, so too will the sophistication and integration of these robotic senses, leading to even more capable and autonomous systems.</p><hr><h2 class="anchor anchorWithStickyNavbar_LWe7" id="key-takeaways">Key Takeaways<a href="#key-takeaways" class="hash-link" aria-label="Direct link to Key Takeaways" title="Direct link to Key Takeaways">​</a></h2><ul><li>Sensors are crucial for robots to perceive their internal state (proprioceptive) and external environment (exteroceptive).</li><li>Proprioceptive sensors include encoders, IMUs, force/torque sensors, and tactile sensors.</li><li>Exteroceptive sensors include various types of cameras (RGB, depth), lidar, radar, and microphones.</li><li>Sensor fusion combines data from multiple sensors for a more accurate and robust environmental understanding.</li><li>ROS 2 provides standard message types and libraries (like <code>cv_bridge</code>) for handling sensor data.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="practice-assignment">Practice Assignment<a href="#practice-assignment" class="hash-link" aria-label="Direct link to Practice Assignment" title="Direct link to Practice Assignment">​</a></h2><ol><li>Research and compare the principles of operation for structured light vs. Time-of-Flight (ToF) depth cameras. Discuss their respective advantages and disadvantages for humanoid robot applications.</li><li>Design a sensor suite for a humanoid robot intended to assist in a smart home environment. Justify your sensor choices based on the tasks the robot would perform (e.g., fetching objects, interacting with residents, navigating cluttered rooms).</li><li>Write a basic ROS 2 Python node that simulates an IMU. Publish <code>sensor_msgs/msg/Imu</code> messages to a topic <code>/humanoid/imu_data</code> at 10 Hz, with dummy (but changing) linear acceleration and angular velocity values. Visualize the output in RViz (using an IMU display if available).</li></ol></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/05-sensors-in-physical-ai.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/urdf-and-robot-description"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">URDF and Robot Description</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/simulation-with-gazebo"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Simulation with Gazebo</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#the-eyes-ears-and-touch-of-a-robot" class="table-of-contents__link toc-highlight">The Eyes, Ears, and Touch of a Robot</a><ul><li><a href="#importance-of-sensory-perception" class="table-of-contents__link toc-highlight">Importance of Sensory Perception</a></li></ul></li><li><a href="#categories-of-sensors" class="table-of-contents__link toc-highlight">Categories of Sensors</a><ul><li><a href="#51-proprioceptive-sensors" class="table-of-contents__link toc-highlight">5.1. Proprioceptive Sensors</a></li><li><a href="#52-exteroceptive-sensors" class="table-of-contents__link toc-highlight">5.2. Exteroceptive Sensors</a></li></ul></li><li><a href="#sensor-fusion-the-holistic-view" class="table-of-contents__link toc-highlight">Sensor Fusion: The Holistic View</a></li><li><a href="#sensor-data-processing-in-ros-2" class="table-of-contents__link toc-highlight">Sensor Data Processing in ROS 2</a></li><li><a href="#conclusion" class="table-of-contents__link toc-highlight">Conclusion</a></li><li><a href="#key-takeaways" class="table-of-contents__link toc-highlight">Key Takeaways</a></li><li><a href="#practice-assignment" class="table-of-contents__link toc-highlight">Practice Assignment</a></li></ul></div></div></div></div></main></div></div><button class="chatButton_gSQt" aria-label="Toggle chat"><svg width="28" height="28" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M21 15a2 2 0 0 1-2 2H7l-4 4V5a2 2 0 0 1 2-2h14a2 2 0 0 1 2 2z" stroke-linecap="round" stroke-linejoin="round"></path><circle cx="9" cy="10" r="0.5" fill="currentColor" stroke-width="0"></circle><circle cx="12" cy="10" r="0.5" fill="currentColor" stroke-width="0"></circle><circle cx="15" cy="10" r="0.5" fill="currentColor" stroke-width="0"></circle></svg></button></div>
<script src="/assets/js/runtime~main.a22e79de.js"></script>
<script src="/assets/js/main.8e1e1db1.js"></script>
</body>
</html>