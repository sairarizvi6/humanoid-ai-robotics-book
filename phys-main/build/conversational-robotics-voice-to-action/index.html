<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-conversational-robotics-voice-to-action" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.3">
<title data-rh="true">Conversational Robotics - Voice to Action | Physical AI &amp; Humanoid Robotics: Bridging Digital Intelligence and the Physical World</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://phys-git-main-sairarizvi6-projects.vercel.app/conversational-robotics-voice-to-action"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="chat-api" content="https://phys-chatbot-api.vercel.app/chat"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Conversational Robotics - Voice to Action | Physical AI &amp; Humanoid Robotics: Bridging Digital Intelligence and the Physical World"><meta data-rh="true" name="description" content="Enabling Natural Human-Robot Communication"><meta data-rh="true" property="og:description" content="Enabling Natural Human-Robot Communication"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://phys-git-main-sairarizvi6-projects.vercel.app/conversational-robotics-voice-to-action"><link data-rh="true" rel="alternate" href="https://phys-git-main-sairarizvi6-projects.vercel.app/conversational-robotics-voice-to-action" hreflang="en"><link data-rh="true" rel="alternate" href="https://phys-git-main-sairarizvi6-projects.vercel.app/conversational-robotics-voice-to-action" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.0a5f47d9.css">
<link rel="preload" href="/assets/js/runtime~main.a22e79de.js" as="script">
<link rel="preload" href="/assets/js/main.8e1e1db1.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><b class="navbar__title text--truncate">Physical AI &amp; Humanoid Robotics</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/introduction-to-physical-ai">Textbook</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/panaversity/ai-robotics-textbook" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/introduction-to-physical-ai">Introduction to Physical AI</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/embodied-intelligence-and-humanoids">Embodied Intelligence and Humanoids</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ros2-the-robotic-nervous-system">ROS 2 - The Robotic Nervous System</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/urdf-and-robot-description">URDF and Robot Description</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/sensors-in-physical-ai">Sensors in Physical AI</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/simulation-with-gazebo">Simulation with Gazebo</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/nvidia-isaac-sim-and-digital-twins">NVIDIA Isaac Sim and Digital Twins</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/isaac-ros-and-perception">Isaac ROS and Perception</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/navigation-and-bipedal-locomotion">Navigation and Bipedal Locomotion</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/vision-language-action-models">Vision-Language-Action Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" href="/conversational-robotics-voice-to-action">Conversational Robotics - Voice to Action</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/balance-manipulation-and-whole-body-control">Balance, Manipulation, and Whole-Body Control</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/capstone-autonomous-humanoid">Capstone - Autonomous Humanoid</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/recommended-humanoid-robots">Recommended Humanoid Robots</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/student-hardware-guide">Student Hardware Guide</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/">Welcome to Physical AI &amp; Humanoid Robotics</a></li></ul></nav></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Conversational Robotics - Voice to Action</span><meta itemprop="position" content="1"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Chapter 11: Conversational Robotics: Voice to Action</h1><h2 class="anchor anchorWithStickyNavbar_LWe7" id="enabling-natural-human-robot-communication">Enabling Natural Human-Robot Communication<a href="#enabling-natural-human-robot-communication" class="hash-link" aria-label="Direct link to Enabling Natural Human-Robot Communication" title="Direct link to Enabling Natural Human-Robot Communication">​</a></h2><p>For humanoid robots to truly integrate into human environments, they must be able to communicate naturally and intuitively with people. <strong>Conversational Robotics</strong> focuses on enabling robots to understand spoken language, engage in dialogue, and translate verbal commands into physical actions. This interdisciplinary field combines advancements in speech recognition, natural language understanding (NLU), dialogue management, and robotic control to create seamless and effective human-robot interaction (HRI).</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="the-importance-of-voice-interface">The Importance of Voice Interface<a href="#the-importance-of-voice-interface" class="hash-link" aria-label="Direct link to The Importance of Voice Interface" title="Direct link to The Importance of Voice Interface">​</a></h3><ul><li><strong>Natural Interaction</strong>: Voice is the most intuitive form of communication for humans, eliminating the need for complex interfaces.</li><li><strong>Accessibility</strong>: Provides an alternative interaction method for individuals with motor impairments or those who find graphical interfaces challenging.</li><li><strong>Hands-Free Operation</strong>: Allows users to multitask while interacting with the robot.</li><li><strong>Situational Awareness</strong>: Verbal cues can provide rich context that is difficult to convey through other means.</li></ul><div class="language-mermaid codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-mermaid codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">graph TD</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    A[Human Voice Input] --&gt; B(Speech Recognition)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    B --&gt; C(Natural Language Understanding - NLU)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    C --&gt; D(Dialogue Management)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    D --&gt; E(High-Level Action Planner)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    E --&gt; F[Robot Control System]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    F --&gt; G[Robot Physical Action]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    F --&gt; H(Natural Language Generation - NLG)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    H --&gt; I(Text-to-Speech)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    I --&gt; J[Robot Voice Output]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><em>Figure 11.1: End-to-end pipeline for conversational robotics.</em></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="key-components-of-conversational-robotics">Key Components of Conversational Robotics<a href="#key-components-of-conversational-robotics" class="hash-link" aria-label="Direct link to Key Components of Conversational Robotics" title="Direct link to Key Components of Conversational Robotics">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="111-speech-recognition-automatic-speech-recognition---asr">11.1. Speech Recognition (Automatic Speech Recognition - ASR)<a href="#111-speech-recognition-automatic-speech-recognition---asr" class="hash-link" aria-label="Direct link to 11.1. Speech Recognition (Automatic Speech Recognition - ASR)" title="Direct link to 11.1. Speech Recognition (Automatic Speech Recognition - ASR)">​</a></h3><p>ASR systems convert spoken words into text. For robotics, this involves robust performance in noisy environments and understanding diverse accents and speech patterns. Modern ASR leverages deep learning models (e.g., Transformers, Recurrent Neural Networks).</p><ul><li><strong>Challenges</strong>: Background noise, multiple speakers, accents, varying speech rates, domain-specific terminology.</li><li><strong>ROS 2 Integration</strong>: Often uses external cloud-based APIs (Google Speech-to-Text, Azure Speech) or on-device engines (e.g., Vosk, NVIDIA Riva) integrated via ROS 2 nodes.</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="112-natural-language-understanding-nlu">11.2. Natural Language Understanding (NLU)<a href="#112-natural-language-understanding-nlu" class="hash-link" aria-label="Direct link to 11.2. Natural Language Understanding (NLU)" title="Direct link to 11.2. Natural Language Understanding (NLU)">​</a></h3><p>NLU processes the transcribed text to extract its meaning, intent, and relevant entities. This is crucial for translating human commands into machine-executable formats.</p><ul><li><strong>Intent Recognition</strong>: Identifying the user&#x27;s goal (e.g., &quot;navigate&quot;, &quot;pick_up&quot;, &quot;report_status&quot;).</li><li><strong>Entity Extraction</strong>: Identifying key pieces of information (e.g., &quot;blue cup&quot;, &quot;kitchen&quot;, &quot;table&quot;).</li><li><strong>Dialogue Act Classification</strong>: Understanding the communicative function of an utterance (e.g., question, command, confirmation).</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="113-dialogue-management-dm">11.3. Dialogue Management (DM)<a href="#113-dialogue-management-dm" class="hash-link" aria-label="Direct link to 11.3. Dialogue Management (DM)" title="Direct link to 11.3. Dialogue Management (DM)">​</a></h3><p>DM manages the flow of the conversation, keeping track of context, resolving ambiguities, and determining the robot&#x27;s next response or action. This often involves state machines or more advanced neural dialogue models.</p><ul><li><strong>Context Tracking</strong>: Remembering previous turns and relevant information.</li><li><strong>Disambiguation</strong>: Asking clarifying questions when commands are vague (e.g., &quot;Which cup do you mean?&quot;).</li><li><strong>Turn-Taking</strong>: Ensuring natural conversational flow.</li></ul><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token comment" style="color:rgb(98, 114, 164)"># Conceptual Python snippet: NLU and Dialogue State Update</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># In a real system, this would involve complex ML models and state management</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">class</span><span class="token plain"> </span><span class="token class-name">DialogueManager</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(80, 250, 123)">__init__</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">context </span><span class="token operator">=</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">robot_state </span><span class="token operator">=</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;location&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;living_room&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;holding&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token boolean">None</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(80, 250, 123)">process_utterance</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> text</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        intent </span><span class="token operator">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">nlu_model</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">get_intent</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">text</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        entities </span><span class="token operator">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">nlu_model</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">get_entities</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">text</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        response_text </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        action_command </span><span class="token operator">=</span><span class="token plain"> </span><span class="token boolean">None</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">if</span><span class="token plain"> intent </span><span class="token operator">==</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;navigate_to&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            target_location </span><span class="token operator">=</span><span class="token plain"> entities</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">get</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;location&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">if</span><span class="token plain"> target_location</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                action_command </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">f&quot;navigate(</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token string-interpolation interpolation">target_location</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">)&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                response_text </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">f&quot;Navigating to </span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token string-interpolation interpolation">target_location</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">.&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">robot_state</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;location&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> target_location </span><span class="token comment" style="color:rgb(98, 114, 164)"># Update state</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">else</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                response_text </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;Where would you like me to go?&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">elif</span><span class="token plain"> intent </span><span class="token operator">==</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;pickup_object&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            target_object </span><span class="token operator">=</span><span class="token plain"> entities</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">get</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;object&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">if</span><span class="token plain"> target_object</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                action_command </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">f&quot;pickup(</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token string-interpolation interpolation">target_object</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">)&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                response_text </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">f&quot;Attempting to pick up the </span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token string-interpolation interpolation">target_object</span><span class="token string-interpolation interpolation punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token string-interpolation string" style="color:rgb(255, 121, 198)">.&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">robot_state</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;holding&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> target_object </span><span class="token comment" style="color:rgb(98, 114, 164)"># Update state</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">else</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                response_text </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;What should I pick up?&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">else</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            response_text </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;I&#x27;m sorry, I didn&#x27;t understand that.&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">return</span><span class="token plain"> response_text</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> action_command</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Example usage</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># dm = DialogueManager()</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># text_input = &quot;Go to the kitchen&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># response, action = dm.process_utterance(text_input)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># print(response) # &quot;Navigating to kitchen.&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># print(action)   # &quot;navigate(kitchen)&quot;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><em>Code 11.1: Simplified Python class for NLU and dialogue state management.</em></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="114-natural-language-generation-nlg-and-text-to-speech-tts">11.4. Natural Language Generation (NLG) and Text-to-Speech (TTS)<a href="#114-natural-language-generation-nlg-and-text-to-speech-tts" class="hash-link" aria-label="Direct link to 11.4. Natural Language Generation (NLG) and Text-to-Speech (TTS)" title="Direct link to 11.4. Natural Language Generation (NLG) and Text-to-Speech (TTS)">​</a></h3><p>NLG is the process of generating human-like text responses from structured data or dialogue states. TTS then converts this text into spoken audio, allowing the robot to speak its responses.</p><ul><li><strong>NLG</strong>: Can use rule-based systems or advanced generative LLMs.</li><li><strong>TTS</strong>: Converts text to speech, often using neural networks for natural-sounding voices.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="voice-to-action-integration">Voice-to-Action Integration<a href="#voice-to-action-integration" class="hash-link" aria-label="Direct link to Voice-to-Action Integration" title="Direct link to Voice-to-Action Integration">​</a></h2><p>The ultimate goal is to seamlessly integrate the conversational components with the robot&#x27;s physical action capabilities. This often means mapping high-level action commands from the dialogue manager to the robot&#x27;s planning and control systems.</p><ul><li><strong>ROS 2 Actions/Services</strong>: High-level commands (e.g., <code>navigate(target_location)</code>, <code>pickup(object)</code>) can be translated into ROS 2 action goals or service requests for the robot&#x27;s motion planning and manipulation stacks.</li><li><strong>Vision-Language Grounding</strong>: Crucial for commands involving specific objects (e.g., &quot;pick up <em>that</em> red box&quot;), where the NLU output must be grounded in the visual perception of the scene.</li></ul><div class="language-mermaid codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-mermaid codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">sequenceDiagram</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    actor User</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    participant ASR</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    participant NLU</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    participant DM</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    participant ActionPlanner</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    participant Robot</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    User-&gt;&gt;ASR: &quot;Robot, fetch the book from the desk.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ASR-&gt;&gt;NLU: &quot;robot fetch the book from the desk&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    NLU-&gt;&gt;DM: Intent: fetch_object, Object: book, Location: desk</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    DM-&gt;&gt;DM: Update Dialogue State, Ground Entities (Vision-Language Models)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    DM-&gt;&gt;ActionPlanner: Goal: pick_up(book, desk)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ActionPlanner-&gt;&gt;Robot: Navigate(desk), Manipulate(book)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    Robot-&gt;&gt;Robot: Execute Actions</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    Robot-&gt;&gt;DM: Action Complete: book_picked_up</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    DM-&gt;&gt;NLU: Generate Response: &quot;I have the book.&quot;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    NLU-&gt;&gt;User: (via TTS) &quot;I have the book.&quot;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><em>Figure 11.2: Detailed voice-to-action sequence.</em></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="challenges-and-future-directions">Challenges and Future Directions<a href="#challenges-and-future-directions" class="hash-link" aria-label="Direct link to Challenges and Future Directions" title="Direct link to Challenges and Future Directions">​</a></h2><p>Conversational robotics faces significant challenges:</p><ul><li><strong>Robustness to Errors</strong>: Cascading errors from ASR, NLU, or action failures.</li><li><strong>Common Sense Reasoning</strong>: Robots still lack deep common sense needed for truly intelligent conversations and actions.</li><li><strong>Personalization</strong>: Adapting to individual user&#x27;s speech patterns, preferences, and social cues.</li><li><strong>Proactive Interaction</strong>: Initiating conversations or offering help without explicit prompts.</li><li><strong>Multimodal Dialogue</strong>: Incorporating gestures, facial expressions, and visual context into the conversation.</li></ul><p>Future advancements will likely involve end-to-end differentiable VLA models, more powerful foundation models for HRI, and continuous learning from human interaction to improve conversational fluency and physical competence.</p><hr><h2 class="anchor anchorWithStickyNavbar_LWe7" id="key-takeaways">Key Takeaways<a href="#key-takeaways" class="hash-link" aria-label="Direct link to Key Takeaways" title="Direct link to Key Takeaways">​</a></h2><ul><li>Conversational Robotics enables robots to interact naturally using spoken language, translating voice commands into physical actions.</li><li>Key components include Speech Recognition (ASR), Natural Language Understanding (NLU), Dialogue Management (DM), Natural Language Generation (NLG), and Text-to-Speech (TTS).</li><li>Voice-to-action integration maps high-level commands from NLU/DM to robot planning and control systems, often leveraging ROS 2 actions/services.</li><li>Vision-language grounding is crucial for commands involving specific objects in the environment.</li><li>Challenges include robustness, common sense reasoning, personalization, and multimodal dialogue.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="practice-assignment">Practice Assignment<a href="#practice-assignment" class="hash-link" aria-label="Direct link to Practice Assignment" title="Direct link to Practice Assignment">​</a></h2><ol><li>Consider a humanoid robot serving as a receptionist. Design a simple dialogue flow (using conditional statements or a state machine) for a user asking the robot to &quot;Call a taxi for me.&quot; Include steps for clarifying destination, confirming, and reporting status.</li><li>Research the NVIDIA Riva SDK for conversational AI. How does Riva contribute to building on-device, low-latency conversational interfaces for robotics, and what are its key advantages over purely cloud-based solutions?</li><li>(Conceptual) Outline a Python script that integrates a mock ASR output with a simple NLU component (e.g., using a dictionary for intent/entity mapping) and then prints a corresponding high-level robot action command. For instance, if input is &quot;go to kitchen&quot;, output <code>ACTION: NAVIGATE, LOCATION: kitchen</code>.</li></ol></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/11-conversational-robotics-voice-to-action.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/vision-language-action-models"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Vision-Language-Action Models</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/balance-manipulation-and-whole-body-control"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Balance, Manipulation, and Whole-Body Control</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#enabling-natural-human-robot-communication" class="table-of-contents__link toc-highlight">Enabling Natural Human-Robot Communication</a><ul><li><a href="#the-importance-of-voice-interface" class="table-of-contents__link toc-highlight">The Importance of Voice Interface</a></li></ul></li><li><a href="#key-components-of-conversational-robotics" class="table-of-contents__link toc-highlight">Key Components of Conversational Robotics</a><ul><li><a href="#111-speech-recognition-automatic-speech-recognition---asr" class="table-of-contents__link toc-highlight">11.1. Speech Recognition (Automatic Speech Recognition - ASR)</a></li><li><a href="#112-natural-language-understanding-nlu" class="table-of-contents__link toc-highlight">11.2. Natural Language Understanding (NLU)</a></li><li><a href="#113-dialogue-management-dm" class="table-of-contents__link toc-highlight">11.3. Dialogue Management (DM)</a></li><li><a href="#114-natural-language-generation-nlg-and-text-to-speech-tts" class="table-of-contents__link toc-highlight">11.4. Natural Language Generation (NLG) and Text-to-Speech (TTS)</a></li></ul></li><li><a href="#voice-to-action-integration" class="table-of-contents__link toc-highlight">Voice-to-Action Integration</a></li><li><a href="#challenges-and-future-directions" class="table-of-contents__link toc-highlight">Challenges and Future Directions</a></li><li><a href="#key-takeaways" class="table-of-contents__link toc-highlight">Key Takeaways</a></li><li><a href="#practice-assignment" class="table-of-contents__link toc-highlight">Practice Assignment</a></li></ul></div></div></div></div></main></div></div><button class="chatButton_gSQt" aria-label="Toggle chat"><svg width="28" height="28" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M21 15a2 2 0 0 1-2 2H7l-4 4V5a2 2 0 0 1 2-2h14a2 2 0 0 1 2 2z" stroke-linecap="round" stroke-linejoin="round"></path><circle cx="9" cy="10" r="0.5" fill="currentColor" stroke-width="0"></circle><circle cx="12" cy="10" r="0.5" fill="currentColor" stroke-width="0"></circle><circle cx="15" cy="10" r="0.5" fill="currentColor" stroke-width="0"></circle></svg></button></div>
<script src="/assets/js/runtime~main.a22e79de.js"></script>
<script src="/assets/js/main.8e1e1db1.js"></script>
</body>
</html>